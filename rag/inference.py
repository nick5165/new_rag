import re
from langchain_core.messages import SystemMessage, HumanMessage
from langchain.output_parsers import PydanticOutputParser
from files_processing.models import model, vector_store
from query.answer_schema import Topic

def get_response(user_query):
    parser = PydanticOutputParser(pydantic_object=Topic)

    def clean_response(text):
        return re.sub(r"``````", "", text, flags=re.IGNORECASE).strip()

    def parse_topic_articles(llm_response):
        cleaned_text = clean_response(llm_response)
        try:
            return parser.parse(cleaned_text)
        except Exception as e:
            return None
        
    def format_topic(topic_obj):
        if not topic_obj:
            return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã"
        
        result = []
        result.append(f"üìö –¢–µ–º–∞: {topic_obj.topic}")
        result.append(f"üìù –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:\n{topic_obj.description.replace('\\n', '\n')}\n")
        result.append("üìã –°—Ç–∞—Ç—å–∏:")

        if not topic_obj.laws:
            result.append("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
        else:
            for i, article in enumerate(topic_obj.laws, 1):
                result.append(f"\n{i}. –°—Ç–∞—Ç—å—è:")
                result.append(article.article.replace("\\n", "\n").replace('\n\n', '\n'))
                result.append("   üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ:")
                result.append(article.explanation.replace("\\n", "\n").replace('\n\n', '\n'))
                result.append("   üìë –ü–æ–¥–ø—É–Ω–∫—Ç—ã:")
                result.append(article.subparagraphs.replace("\\n", "\n").replace('\n\n', '\n'))
                
        return "\n".join(result)
    
    try:
        relevant_docs = vector_store.similarity_search(user_query, k=3)
        context = "\n\n".join(doc.page_content for doc in relevant_docs)

        system_prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç—Ä—É–¥–æ–≤–æ–º—É –ø—Ä–∞–≤—É –†–æ—Å—Å–∏–∏. 
–í–æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:

{context}

–û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:

{parser.get_format_instructions()}

–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ laws.
"""
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_query)
        ]

        response = model.invoke(messages)
        topic_result = parse_topic_articles(response.content)
        formatted_output = format_topic(topic_result)

        return {
            'succes': True,
            'response': formatted_output,
            'raw_data': topic_result
        }
    except Exception as e:
        return {
            'succes': False,
            'error': f"–û—à–∏–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
            'response': "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
        }